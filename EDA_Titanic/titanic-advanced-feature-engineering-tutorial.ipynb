{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b92c0af57d3a181c7b72fce0a2e5b20164bd518b",
    "id": "nniFvpoWTrkm"
   },
   "source": [
    "# **0. Introduction**\n",
    "- 3개의 주요 세션이 있음: EDA, feature engineering, Model\n",
    "- 랜덤포레스트 상위 2% 달성됨(0.83)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": false,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "qXHo4_FlTrkp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7dc1cb7b8813f315a8b30fd636b3d46b4270496",
    "id": "MUYyE6WYTrkq"
   },
   "source": [
    "* Training set has **891** rows and test set has **418** rows\n",
    "* Training set have **12** features and test set have **11** features\n",
    "* One extra feature in training set is `Survived` feature, which is the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1628407380079,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "P7rIDXCIUJVt",
    "outputId": "9909b681-8393-42fd-dde8-8f01e7265cd5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z8/ww0840b942j9jdtcy3pyn68c0000gn/T/ipykernel_64214/1958918533.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# colab 드라이브 마운트\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# colab 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628407380080,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "ef9K0aqwUkah",
    "outputId": "0e8fa137-ef83-41c4-8b70-62d16ac99490"
   },
   "outputs": [],
   "source": [
    "# 현재 폴더 경로 확인\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oF94VLe6Utga"
   },
   "outputs": [],
   "source": [
    "# 폴더 이동 \"/content/gdrive/MyDrive\"\n",
    "os.chdir('/content/gdrive/MyDrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628407380491,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "UEKc2xhmUqmB",
    "outputId": "86bc1fef-57d3-4c10-c68f-846754b22ffb"
   },
   "outputs": [],
   "source": [
    "# 현재 경로의 하위 폴더, 파일 확인\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "467443fda7135a8ce89c4d537da3f3a8546e2384",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628407380865,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "r2bZntGLTrkr",
    "outputId": "0b720173-d6d6-4d65-c1f2-5a9f577d1816"
   },
   "outputs": [],
   "source": [
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "def divide_df(all_data):\n",
    "    # Returns divided dfs of training and test set\n",
    "    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
    "print('Training X Shape = {}'.format(df_train.shape))\n",
    "print('Training y Shape = {}\\n'.format(df_train['Survived'].shape[0]))\n",
    "print('Test X Shape = {}'.format(df_test.shape))\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628407380865,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "Y6SnNummQayM",
    "outputId": "8eff6dd8-9a47-4a96-923c-65912f75421f"
   },
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1628407381184,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "sHAwhef9RcK5",
    "outputId": "b193ec21-548a-4cae-ed9a-21a1690a4417"
   },
   "outputs": [],
   "source": [
    "df_train.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1628407381531,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "fvKyFDKZQeSY",
    "outputId": "4aa1d007-4579-4528-83b1-37fb1572e2cd"
   },
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1628407383380,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "Qw1fJ3XxQ_Q_",
    "outputId": "88f77a80-fea2-4af2-aeb5-c88626b045bb"
   },
   "outputs": [],
   "source": [
    "type(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfabd70ff1cbd50e3107727e5bb630aa59110d83",
    "id": "X9HOMC66Trkr"
   },
   "source": [
    "## **1. Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff42f5c4bad84e23f78fa56b9e1a72abf577942d",
    "id": "k7LxL8sxTrks"
   },
   "source": [
    "### **1.1 Overview**\n",
    "\n",
    "\n",
    "# 데이터셋 설명\n",
    "- Survived - 생존 여부 (0 = 사망, 1 = 생존)\n",
    "- Pclass - 티켓 클래스 (1 = 1등석, 2 = 2등석, 3 = 3등석)\n",
    "- Sex - 성별\n",
    "- Age - 나이\n",
    "- SibSp - 함께 탑승한 자녀 / 배우자 의 수\n",
    "- Parch - 함께 탑승한 부모님 / 아이들 의 수\n",
    "- Ticket - 티켓 번호\n",
    "- Fare - 탑승 요금\n",
    "- Cabin - 수하물 번호\n",
    "- Embarked - 선착장 (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "f02f321f8fd8b8c7c2a4aedb36ebe868ae51004e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "executionInfo": {
     "elapsed": 271,
     "status": "ok",
     "timestamp": 1628407384679,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "xJ7f7ExjTrkt",
    "outputId": "33be160e-0994-4027-fb87-5c7c7ae3e79b"
   },
   "outputs": [],
   "source": [
    "print(df_train.info())\n",
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "851ccf74127831d31ea0d7273b686f9a7cf20eee",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628407385077,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "deqAd5E0Trkt",
    "outputId": "148acef2-4c3f-4703-ec1b-b16744174a54"
   },
   "outputs": [],
   "source": [
    "print(df_test.info())\n",
    "df_test.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3db8a853b0b33256f1b08f77d7edf0e9d1737d62",
    "id": "L_I-tlSYTrku"
   },
   "source": [
    "### **1.2 Missing Values**\n",
    "As seen from below, some columns have missing values. `display_missing` function shows the count of missing values in every column in both training and test set.\n",
    "* Training set have missing values in `Age`, `Cabin` and `Embarked` columns\n",
    "* Test set have missing values in `Age`, `Cabin` and `Fare` columns\n",
    "\n",
    "It is convenient to work on concatenated training and test set while dealing with missing values, otherwise filled data may overfit to training or test set samples. The count of missing values in `Age`, `Embarked` and `Fare` are smaller compared to total sample, but roughly **80%** of the `Cabin` is missing. Missing values in `Age`, `Embarked` and `Fare` can be filled with descriptive statistical measures but that wouldn't work for `Cabin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d4e8f7b72e2bd165cafa71d67c95f008e7c6101d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1628407387100,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "Z2gkqNPNTrkv",
    "outputId": "02fd7449-cace-4d85-9a4b-701c3bc8b71b"
   },
   "outputs": [],
   "source": [
    "def display_missing(df):    \n",
    "    for col in df.columns.tolist():          \n",
    "        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "    print('\\n')\n",
    "    \n",
    "for df in dfs:\n",
    "    print('{}'.format(df.name))\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUY9msSZOW-S"
   },
   "source": [
    "# [발표대상] **1.2.1 Age**  \n",
    "- 승객의 연령에 대한 결측값 처리 방안\n",
    "- 전체 연령의 평균을 사용하는 방식이 아닌, 1) 상관관계 분석  2) 상관성이 가장 높은 변수 기준의 중앙값 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GK7hhhI1Trkw"
   },
   "source": [
    "#### **1.2.1 Age**\n",
    "Missing values in `Age` are filled with median age, but using median age of the whole data set is not a good choice. Median age of `Pclass` groups is the best choice because of its high correlation with `Age` **(0.408106)** and `Survived` **(0.338481)**. It is also more logical to group ages by passenger classes instead of other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628407388214,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "yPvkWgg-Sv5i",
    "outputId": "4d619eed-4557-41a2-d53d-3b802491d30b"
   },
   "outputs": [],
   "source": [
    "df_all.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1628407388562,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "dRq5MhjqTrkw",
    "outputId": "1a5e3f91-2399-4d64-ebcf-f8ba96235e29"
   },
   "outputs": [],
   "source": [
    "df_all_corr = df_all.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "df_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "df_all_corr[df_all_corr['Feature 1'] == 'Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k94L_aV9Trkw"
   },
   "source": [
    "In order to be more accurate, `Sex` feature is used as the second level of `groupby` while filling the missing `Age` values. As seen from below, `Pclass` and `Sex` groups have distinct median `Age` values. When passenger class increases, the median age for both males and females also increases. However, females tend to have slightly lower median `Age` than males. The median ages below are used for filling the missing values in `Age` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 278,
     "status": "ok",
     "timestamp": 1628407390043,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "jg1MffBKTrkx",
    "outputId": "27e02e95-09c1-484e-d496-54682d6fb237"
   },
   "outputs": [],
   "source": [
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "\n",
    "for pclass in range(1, 4):\n",
    "    for sex in ['female', 'male']:\n",
    "        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n",
    "print('Median age of all passengers: {}'.format(df_all['Age'].median()))\n",
    "\n",
    "# Filling the missing values in Age with the medians of Sex and Pclass groups\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pr0buvxMTrkx"
   },
   "source": [
    "# **1.2.2 Embarked**\n",
    "- `Embarked` 카테고리 변수, 2개의 값이 누락됨\n",
    "- 해당 2명은 여성, 1등급, 80달러 티켓 보유, 하인과 주인이 같이 승선, PClass가 가장 많은 C(Cherbourg)로 추정함\n",
    "- 최종은 구글에서 해당 Name으로 검색하여 S\n",
    "\n",
    "is a categorical feature and there are only **2** missing values in whole data set. Both of those passengers are female, upper class and they have the same ticket number. This means that they know each other and embarked from the same port together. The mode `Embarked` value for an upper class female passenger is **C (Cherbourg)**, but this doesn't necessarily mean that they embarked from that port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628407390830,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "w-gNmAN-bfK0",
    "outputId": "84e24f0e-0a04-4cc2-dfe5-b5385ff6a52d"
   },
   "outputs": [],
   "source": [
    "df_all.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1628407391861,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "Uwfp_AwXaVVG",
    "outputId": "b4a992fb-49e0-4ba6-a06f-99f4b9239837"
   },
   "outputs": [],
   "source": [
    "df_all[  (df_all['Pclass'] == 1 ) &(df_all['Sex'] == 'female' ) ]['Embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1628407393905,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "XS9wf3mIdii4",
    "outputId": "1208ae5b-7cca-45d0-f069-148a6643badb"
   },
   "outputs": [],
   "source": [
    "df_all[ (df_all['Embarked'] == 'S' ) ]['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1628407394302,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "w1cmKWVMTrkx",
    "outputId": "ec549491-f858-4c83-de8e-6a5854704a2c"
   },
   "outputs": [],
   "source": [
    "df_all[df_all['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628407394640,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "9fYxHWnseMZO",
    "outputId": "4a469272-f39c-4f0d-ae9c-dc638f7514e2"
   },
   "outputs": [],
   "source": [
    "df_all[df_all['Name'].str.contains('Icard')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIZOXk_jTrkx"
   },
   "source": [
    "When I googled **Stone, Mrs. George Nelson (Martha Evelyn)**, I found that she embarked from **S (Southampton)** with her maid **Amelie Icard**, in this page [Martha Evelyn Stone: Titanic Survivor](https://www.encyclopedia-titanica.org/titanic-survivor/martha-evelyn-stone.html).\n",
    "\n",
    "> *Mrs Stone boarded the Titanic in Southampton on 10 April 1912 and was travelling in first class with her maid Amelie Icard. She occupied cabin B-28.*\n",
    "\n",
    "Missing values in `Embarked` are filled with **S** with this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlvOkPQbTrky"
   },
   "outputs": [],
   "source": [
    "# Filling the missing values in Embarked with S\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_gFp3dlTrky"
   },
   "source": [
    "#### **1.2.3 Fare**\n",
    "There is only one passenger with missing `Fare` value. We can assume that `Fare` is related to family size (`Parch` and `SibSp`) and `Pclass` features. Median `Fare` value of a male with a third class ticket and no family is a logical choice to fill the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1628407397671,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "Vf5sZJpuTrky",
    "outputId": "4e487610-fd90-4105-b80b-559d313ce0a6"
   },
   "outputs": [],
   "source": [
    "df_all[df_all['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "id": "9s3KK0YuTrky"
   },
   "outputs": [],
   "source": [
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1628407399551,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "sMeuRYk8Trky",
    "outputId": "afc44372-cb27-4171-bf11-d544b7af30d7"
   },
   "outputs": [],
   "source": [
    "med_fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weanSYmATrkz"
   },
   "source": [
    "#### **1.2.4 Cabin**\n",
    "`Cabin` feature is little bit tricky and it needs further exploration. The large portion of the `Cabin` feature is missing and the feature itself can't be ignored completely because some the cabins might have higher survival rates. It turns out to be the first letter of the `Cabin` values are the decks in which the cabins are located. Those decks were mainly separated for one passenger class, but some of them were used by multiple passenger classes.\n",
    "![alt text](https://vignette.wikia.nocookie.net/titanic/images/f/f9/Titanic_side_plan.png/revision/latest?cb=20180322183733)\n",
    "* On the Boat Deck there were **6** rooms labeled as **T, U, W, X, Y, Z** but only the **T** cabin is present in the dataset\n",
    "* **A**, **B** and **C** decks were only for 1st class passengers\n",
    "* **D** and **E** decks were for all classes\n",
    "* **F** and **G** decks were for both 2nd and 3rd class passengers\n",
    "* From going **A** to **G**, distance to the staircase increases which might be a factor of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "executionInfo": {
     "elapsed": 742,
     "status": "ok",
     "timestamp": 1628407401328,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "UBQx32g4Trkz",
    "outputId": "fe275a9e-c0fa-4190-bbd8-05135f92af12"
   },
   "outputs": [],
   "source": [
    "# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\n",
    "df_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "\n",
    "df_all_decks = df_all.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', \n",
    "                                                                        'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "def get_pclass_dist(df):\n",
    "    \n",
    "    # Creating a dictionary for every passenger class count in every deck\n",
    "    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n",
    "    decks = df.columns.levels[0]    \n",
    "    \n",
    "    for deck in decks:\n",
    "        for pclass in range(1, 4):\n",
    "            try:\n",
    "                count = df[deck][pclass][0]\n",
    "                deck_counts[deck][pclass] = count \n",
    "            except KeyError:\n",
    "                deck_counts[deck][pclass] = 0\n",
    "                \n",
    "    df_decks = pd.DataFrame(deck_counts)    \n",
    "    deck_percentages = {}\n",
    "\n",
    "    # Creating a dictionary for every passenger class percentage in every deck\n",
    "    for col in df_decks.columns:\n",
    "        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]\n",
    "        \n",
    "    return deck_counts, deck_percentages\n",
    "\n",
    "def display_pclass_dist(percentages):\n",
    "    \n",
    "    df_percentages = pd.DataFrame(percentages).transpose()\n",
    "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n",
    "    bar_count = np.arange(len(deck_names))  \n",
    "    bar_width = 0.85\n",
    "    \n",
    "    pclass1 = df_percentages[0]\n",
    "    pclass2 = df_percentages[1]\n",
    "    pclass3 = df_percentages[2]\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n",
    "    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n",
    "    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n",
    "\n",
    "    plt.xlabel('Deck', size=15, labelpad=20)\n",
    "    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n",
    "    plt.xticks(bar_count, deck_names)    \n",
    "    plt.tick_params(axis='x', labelsize=15)\n",
    "    plt.tick_params(axis='y', labelsize=15)\n",
    "    \n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n",
    "    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "all_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\n",
    "display_pclass_dist(all_deck_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5hyjlMgTrkz"
   },
   "source": [
    "* **100%** of **A**, **B** and **C** decks are 1st class passengers\n",
    "* Deck **D** has **87%** 1st class and **13%** 2nd class passengers\n",
    "* Deck **E** has **83%** 1st class, **10%** 2nd class and **7%** 3rd class passengers\n",
    "* Deck **F** has **62%** 2nd class and **38%** 3rd class passengers\n",
    "* **100%** of **G** deck are 3rd class passengers\n",
    "* There is one person on the boat deck in **T** cabin and he is a 1st class passenger. **T** cabin passenger has the closest resemblance to **A** deck passengers so he is grouped with **A** deck\n",
    "* Passengers labeled as **M** are the missing values in `Cabin` feature. I don't think it is possible to find those passengers' real `Deck` so I decided to use **M** like a deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLq0KjlKTrkz"
   },
   "outputs": [],
   "source": [
    "# Passenger in the T deck is changed to A\n",
    "idx = df_all[df_all['Deck'] == 'T'].index\n",
    "df_all.loc[idx, 'Deck'] = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1628407404224,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "rz4HVW4qTrkz",
    "outputId": "08be8af5-dc6c-4a85-c9c6-64a1c1ca46a6"
   },
   "outputs": [],
   "source": [
    "df_all.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "executionInfo": {
     "elapsed": 855,
     "status": "ok",
     "timestamp": 1628407407571,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "9s7ToCM5Trkz",
    "outputId": "69167daf-8fd8-41af-80f8-ba5d7ecf3fa2"
   },
   "outputs": [],
   "source": [
    "df_all_decks_survived = df_all.groupby(['Deck', 'Survived']).count().drop(columns=['Sex', 'Age', 'SibSp', 'Parch', 'Fare', \n",
    "                                                                                   'Embarked', 'Pclass', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name':'Count'}).transpose()\n",
    "\n",
    "def get_survived_dist(df):\n",
    "    \n",
    "    # Creating a dictionary for every survival count in every deck\n",
    "    surv_counts = {'A':{}, 'B':{}, 'C':{}, 'D':{}, 'E':{}, 'F':{}, 'G':{}, 'M':{}}\n",
    "    decks = df.columns.levels[0]    \n",
    "\n",
    "    for deck in decks:\n",
    "        for survive in range(0, 2):\n",
    "            surv_counts[deck][survive] = df[deck][survive][0]\n",
    "            \n",
    "    df_surv = pd.DataFrame(surv_counts)\n",
    "    surv_percentages = {}\n",
    "\n",
    "    for col in df_surv.columns:\n",
    "        surv_percentages[col] = [(count / df_surv[col].sum()) * 100 for count in df_surv[col]]\n",
    "        \n",
    "    return surv_counts, surv_percentages\n",
    "\n",
    "def display_surv_dist(percentages):\n",
    "    \n",
    "    df_survived_percentages = pd.DataFrame(percentages).transpose()\n",
    "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n",
    "    bar_count = np.arange(len(deck_names))  \n",
    "    bar_width = 0.85    \n",
    "\n",
    "    not_survived = df_survived_percentages[0]\n",
    "    survived = df_survived_percentages[1]\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(bar_count, not_survived, color='#b5ffb9', edgecolor='white', width=bar_width, label=\"Not Survived\")\n",
    "    plt.bar(bar_count, survived, bottom=not_survived, color='#f9bc86', edgecolor='white', width=bar_width, label=\"Survived\")\n",
    " \n",
    "    plt.xlabel('Deck', size=15, labelpad=20)\n",
    "    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n",
    "    plt.xticks(bar_count, deck_names)    \n",
    "    plt.tick_params(axis='x', labelsize=15)\n",
    "    plt.tick_params(axis='y', labelsize=15)\n",
    "    \n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n",
    "    plt.title('Survival Percentage in Decks', size=18, y=1.05)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "all_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)\n",
    "display_surv_dist(all_surv_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bee5orOtTrk0"
   },
   "source": [
    "As I suspected, every deck has different survival rates and that information can't be discarded. Deck **B**, **C**, **D** and **E** have the highest survival rates. Those decks are mostly occupied by 1st class passengers. **M** has the lowest survival rate which is mostly occupied by 2nd and 3rd class passengers. To conclude, cabins used by 1st class passengers have higher survival rates than cabins used by 2nd and 3rd class passengers. In my opinion **M** (Missing `Cabin` values) has the lowest survival rate because they couldn't retrieve the cabin data of the victims. That's why I believe labeling that group as **M** is a reasonable way to handle the missing data. It is a unique group with shared characteristics. `Deck` feature has high-cardinality right now so some of the values are grouped with each other based on their similarities.\n",
    "* **A**, **B** and **C** decks are labeled as **ABC** because all of them have only 1st class passengers\n",
    "* **D** and **E** decks are labeled as **DE** because both of them have similar passenger class distribution and same survival rate\n",
    "* **F** and **G** decks are labeled as **FG** because of the same reason above\n",
    "* **M** deck doesn't need to be grouped with other decks because it is very different from others and has the lowest survival rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 391,
     "status": "ok",
     "timestamp": 1628407408324,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "pbsBK5-STrk0",
    "outputId": "2a66dfae-bb73-402c-f0b1-f86fe9862209"
   },
   "outputs": [],
   "source": [
    "df_all['Deck'] = df_all['Deck'].replace(['A', 'B', 'C'], 'ABC')\n",
    "df_all['Deck'] = df_all['Deck'].replace(['D', 'E'], 'DE')\n",
    "df_all['Deck'] = df_all['Deck'].replace(['F', 'G'], 'FG')\n",
    "\n",
    "df_all['Deck'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bdEAEyO1Trk0"
   },
   "source": [
    "After filling the missing values in `Age`, `Embarked`, `Fare` and `Deck` features, there is no missing value left in both training and test set. `Cabin` is dropped because `Deck` feature is used instead of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1628407410353,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "Kqm7PdqnTrk0",
    "outputId": "7334d221-2c79-4aff-9d2d-d510acd97833"
   },
   "outputs": [],
   "source": [
    "# Dropping the Cabin feature\n",
    "df_all.drop(['Cabin'], inplace=True, axis=1)\n",
    "\n",
    "df_train, df_test = divide_df(df_all)\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "for df in dfs:\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83ed6dacdc116214381364c2b456a97253e708ef",
    "id": "MP_ETXEtTrk1"
   },
   "source": [
    "### **1.3 Target Distribution**\n",
    "* **38.38%** (342/891) of training set is **Class 1**\n",
    "* **61.62%** (549/891) of training set is **Class 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c70aa13b7a552beb976574d52c1cd3da1cc1ee5c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 594
    },
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1628407411953,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "9uKus01-Trk1",
    "outputId": "b5ba2407-e195-449c-d03b-a0497d6a8a3c"
   },
   "outputs": [],
   "source": [
    "survived = df_train['Survived'].value_counts()[1]\n",
    "not_survived = df_train['Survived'].value_counts()[0]\n",
    "survived_per = survived / df_train.shape[0] * 100\n",
    "not_survived_per = not_survived / df_train.shape[0] * 100\n",
    "\n",
    "print('{} of {} passengers survived and it is the {:.2f}% of the training set.'.format(survived, df_train.shape[0], survived_per))\n",
    "print('{} of {} passengers didnt survive and it is the {:.2f}% of the training set.'.format(not_survived, df_train.shape[0], not_survived_per))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.countplot(df_train['Survived'])\n",
    "\n",
    "plt.xlabel('Survival', size=15, labelpad=15)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=15)\n",
    "plt.xticks((0, 1), ['Not Survived ({0:.2f}%)'.format(not_survived_per), 'Survived ({0:.2f}%)'.format(survived_per)])\n",
    "plt.tick_params(axis='x', labelsize=13)\n",
    "plt.tick_params(axis='y', labelsize=13)\n",
    "\n",
    "plt.title('Training Set Survival Distribution', size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctRW0DFCTrk1"
   },
   "source": [
    "### **1.4 Correlations**\n",
    "Features are highly correlated with each other and dependent to each other. The highest correlation between features is **0.549500** in training set and **0.577147** in test set (between `Fare` and `Pclass`). The other features are also highly correlated. There are **9** correlations in training set and **6** correlations in test set that are higher than **0.1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "lrVR0qtuTrk1"
   },
   "outputs": [],
   "source": [
    "df_train_corr = df_train.drop(['PassengerId'], axis=1).corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "df_train_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)\n",
    "df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr['Correlation Coefficient'] == 1.0].index)\n",
    "\n",
    "df_test_corr = df_test.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "df_test_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "df_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)\n",
    "df_test_corr_nd = df_test_corr.drop(df_test_corr[df_test_corr['Correlation Coefficient'] == 1.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1628407413540,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "03cbrzmvTrk1",
    "outputId": "36d3c020-bcf0-44b7-e293-fd20ac326abf"
   },
   "outputs": [],
   "source": [
    "# Training set high correlations\n",
    "corr = df_train_corr_nd['Correlation Coefficient'] > 0.1\n",
    "df_train_corr_nd[corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1628407413829,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "E2JzZJgkTrk2",
    "outputId": "2620a859-27d0-4d0b-c7d5-13bd9c2c7e0e"
   },
   "outputs": [],
   "source": [
    "# Test set high correlations\n",
    "corr = df_test_corr_nd['Correlation Coefficient'] > 0.1\n",
    "df_test_corr_nd[corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1746,
     "status": "ok",
     "timestamp": 1628407415572,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "SklcKmhKTrk2",
    "outputId": "52cc04a2-0928-4690-a7ef-581d55823cc5"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(df_train.drop(['PassengerId'], axis=1).corr(), ax=axs[0], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "sns.heatmap(df_test.drop(['PassengerId'], axis=1).corr(), ax=axs[1], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "\n",
    "for i in range(2):    \n",
    "    axs[i].tick_params(axis='x', labelsize=14)\n",
    "    axs[i].tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "axs[0].set_title('Training Set Correlations', size=15)\n",
    "axs[1].set_title('Test Set Correlations', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kII28NUvTrk2"
   },
   "source": [
    "### **1.5 Target Distribution in Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5czFqZnTrk2"
   },
   "source": [
    "#### **1.5.1 Continuous Features**\n",
    "Both of the continuous features (`Age` and `Fare`) have good split points and spikes for a decision tree to learn. One potential problem for both features is, the distribution has more spikes and bumps in training set, but it is smoother in test set. Model may not be able to generalize to test set because of this reason.\n",
    "\n",
    "* Distribution of `Age` feature clearly shows that children younger than 15 has a higher survival rate than any of the other age groups\n",
    "* In distribution of `Fare` feature, the survival rate is higher on distribution tails. The distribution also has positive skew because of the extremely large outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2272,
     "status": "ok",
     "timestamp": 1628407419041,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "JNYV33HfTrk2",
    "outputId": "f62a44fe-6aeb-4f3b-987e-76678d49491e"
   },
   "outputs": [],
   "source": [
    "cont_features = ['Age', 'Fare']\n",
    "surv = df_train['Survived'] == 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))\n",
    "plt.subplots_adjust(right=1.5)\n",
    "\n",
    "for i, feature in enumerate(cont_features):    \n",
    "    # Distribution of survival in feature\n",
    "    sns.distplot(df_train[~surv][feature], label='Not Survived', hist=True, color='#e74c3c', ax=axs[0][i])\n",
    "    sns.distplot(df_train[surv][feature], label='Survived', hist=True, color='#2ecc71', ax=axs[0][i])\n",
    "    \n",
    "    # Distribution of feature in dataset\n",
    "    sns.distplot(df_train[feature], label='Training Set', hist=False, color='#e74c3c', ax=axs[1][i])\n",
    "    sns.distplot(df_test[feature], label='Test Set', hist=False, color='#2ecc71', ax=axs[1][i])\n",
    "    \n",
    "    axs[0][i].set_xlabel('')\n",
    "    axs[1][i].set_xlabel('')\n",
    "    \n",
    "    for j in range(2):        \n",
    "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
    "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
    "    \n",
    "    axs[0][i].legend(loc='upper right', prop={'size': 20})\n",
    "    axs[1][i].legend(loc='upper right', prop={'size': 20})\n",
    "    axs[0][i].set_title('Distribution of Survival in {}'.format(feature), size=20, y=1.05)\n",
    "\n",
    "axs[1][0].set_title('Distribution of {} Feature'.format('Age'), size=20, y=1.05)\n",
    "axs[1][1].set_title('Distribution of {} Feature'.format('Fare'), size=20, y=1.05)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1D_S2U42Trk2"
   },
   "source": [
    "#### **1.5.2 Categorical Features**\n",
    "Every categorical feature has at least one class with high mortality rate. Those classes are very helpful to predict whether the passenger is a survivor or victim. Best categorical features are `Pclass` and `Sex` because they have the most homogenous distributions.\n",
    "\n",
    "* Passengers boarded from **Southampton** has a lower survival rate unlike other ports. More than half of the passengers boarded from **Cherbourg** had survived. This observation could be related to `Pclass` feature\n",
    "* `Parch` and `SibSp` features show that passengers with only one family member has a higher survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1628407420525,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "2sT8hYriTrk2",
    "outputId": "09496c63-d733-41d3-84d5-c25769be5ff3"
   },
   "outputs": [],
   "source": [
    "cat_features = ['Embarked', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Deck']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))\n",
    "plt.subplots_adjust(right=1.5, top=1.25)\n",
    "\n",
    "for i, feature in enumerate(cat_features, 1):    \n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=feature, hue='Survived', data=df_train)\n",
    "    \n",
    "    plt.xlabel('{}'.format(feature), size=20, labelpad=15)\n",
    "    plt.ylabel('Passenger Count', size=20, labelpad=15)    \n",
    "    plt.tick_params(axis='x', labelsize=20)\n",
    "    plt.tick_params(axis='y', labelsize=20)\n",
    "    \n",
    "    plt.legend(['Not Survived', 'Survived'], loc='upper center', prop={'size': 18})\n",
    "    plt.title('Count of Survival in {} Feature'.format(feature), size=20, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FdxNPw4Trk2"
   },
   "source": [
    "### **1.6 Conclusion**\n",
    "Most of the features are correlated with each other. This relationship can be used to create new features with feature transformation and feature interaction. Target encoding could be very useful as well because of the high correlations with `Survived` feature.\n",
    "\n",
    "Split points and spikes are visible in continuous features. They can be captured easily with a decision tree model, but linear models may not be able to spot them.\n",
    "\n",
    "Categorical features have very distinct distributions with different survival rates. Those features can be one-hot encoded. Some of those features may be combined with each other to make new features.\n",
    "\n",
    "Created a new feature called `Deck` and dropped `Cabin` feature at the **Exploratory Data Analysis** part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1628407420525,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "mPsO-_x8Trk3",
    "outputId": "a04ed7f0-1e4e-478b-bda0-4302e46e5df7"
   },
   "outputs": [],
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e14506a365afef0af44894e46642acf27ac2545f",
    "id": "lF8kG3geTrk3"
   },
   "source": [
    "## **2. Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pp-j-OUpTrk3"
   },
   "source": [
    "### **2.1 Binning Continuous Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ot4FYYtPTrk3"
   },
   "source": [
    "#### **2.1.1 Fare**\n",
    "`Fare` feature is positively skewed and survival rate is extremely high on the right end. **13** quantile based bins are used for `Fare` feature. Even though the bins are too much, they provide decent amount of information gain. The groups at the left side of the graph has the lowest survival rate and the groups at the right side of the graph has the highest survival rate. This high survival rate was not visible in the distribution graph. There is also an unusual group **(15.742, 23.25]** in the middle with high survival rate that is captured in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RE0mIN-Trk3"
   },
   "outputs": [],
   "source": [
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1628407424758,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "kc_pljjHTrk3",
    "outputId": "a2bd34c7-34bb-43a5-b7d9-7fe7c7804ff2"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(22, 9))\n",
    "sns.countplot(x='Fare', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Fare', size=15, labelpad=20)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=10)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Count of Survival in {} Feature'.format('Fare'), size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UJuP5rhTrk3"
   },
   "source": [
    "#### **2.1.2 Age**\n",
    "`Age` feature has a normal distribution with some spikes and bumps and **10** quantile based bins are used for `Age`. The first bin has the highest survival rate and 4th bin has the lowest survival rate. Those were the biggest spikes in the distribution. There is also an unusual group **(34.0, 40.0]** with high survival rate that is captured in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGD2_Qb7Trk3"
   },
   "outputs": [],
   "source": [
    "df_all['Age'] = pd.qcut(df_all['Age'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "executionInfo": {
     "elapsed": 511,
     "status": "ok",
     "timestamp": 1628407425263,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "Nak46uFzTrk3",
    "outputId": "0c5b36a4-91ba-4066-820d-4453831e5cfb"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(22, 9))\n",
    "sns.countplot(x='Age', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Age', size=15, labelpad=20)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Survival Counts in {} Feature'.format('Age'), size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgjL_vbuTrk4"
   },
   "source": [
    "### **2.2 Frequency Encoding**\n",
    "`Family_Size` is created by adding `SibSp`, `Parch` and **1**. `SibSp` is the count of siblings and spouse, and `Parch` is the count of parents and children. Those columns are added in order to find the total size of families. Adding **1** at the end, is the current passenger. Graphs have clearly shown that family size is a predictor of survival because different values have different survival rates.\n",
    "* Family Size with **1** are labeled as **Alone**\n",
    "* Family Size with **2**, **3** and **4** are labeled as **Small**\n",
    "* Family Size with **5** and **6** are labeled as **Medium**\n",
    "* Family Size with **7**, **8** and **11** are labeled as **Large**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1368,
     "status": "ok",
     "timestamp": 1628407426628,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "cjal9Dw2Trk4",
    "outputId": "104f3931-5f5e-43fd-838d-161f0da8ab58"
   },
   "outputs": [],
   "source": [
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)\n",
    "plt.subplots_adjust(right=1.5)\n",
    "\n",
    "sns.barplot(x=df_all['Family_Size'].value_counts().index, y=df_all['Family_Size'].value_counts().values, ax=axs[0][0])\n",
    "sns.countplot(x='Family_Size', hue='Survived', data=df_all, ax=axs[0][1])\n",
    "\n",
    "axs[0][0].set_title('Family Size Feature Value Counts', size=20, y=1.05)\n",
    "axs[0][1].set_title('Survival Counts in Family Size ', size=20, y=1.05)\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "\n",
    "sns.barplot(x=df_all['Family_Size_Grouped'].value_counts().index, y=df_all['Family_Size_Grouped'].value_counts().values, ax=axs[1][0])\n",
    "sns.countplot(x='Family_Size_Grouped', hue='Survived', data=df_all, ax=axs[1][1])\n",
    "\n",
    "axs[1][0].set_title('Family Size Feature Value Counts After Grouping', size=20, y=1.05)\n",
    "axs[1][1].set_title('Survival Counts in Family Size After Grouping', size=20, y=1.05)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i][1].legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 20})\n",
    "    for j in range(2):\n",
    "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
    "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
    "        axs[i][j].set_xlabel('')\n",
    "        axs[i][j].set_ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqgguZcCTrk4"
   },
   "source": [
    "There are too many unique `Ticket` values to analyze, so grouping them up by their frequencies makes things easier.\n",
    "\n",
    "**How is this feature different than `Family_Size`?** Many passengers travelled along with groups. Those groups consist of friends, nannies, maids and etc. They weren't counted as family, but they used the same ticket.\n",
    "\n",
    "**Why not grouping tickets by their prefixes?** If prefixes in `Ticket` feature has any meaning, then they are already captured in `Pclass` or `Embarked` features because that could be the only logical information which can be derived from the `Ticket` feature.\n",
    "\n",
    "According to the graph below, groups with **2**,**3** and **4** members had a higher survival rate. Passengers who travel alone has the lowest survival rate. After **4** group members, survival rate decreases drastically. This pattern is very similar to `Family_Size` feature but there are minor differences. `Ticket_Frequency` values are not grouped like `Family_Size` because that would basically create the same feature with perfect correlation. This kind of feature wouldn't provide any additional information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8o1vktvTrk4"
   },
   "outputs": [],
   "source": [
    "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628407428846,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "_m9sw7E2Trk4",
    "outputId": "279114e6-7a94-492f-e9b9-cc76b2845715"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 9))\n",
    "sns.countplot(x='Ticket_Frequency', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Ticket Frequency', size=15, labelpad=20)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Count of Survival in {} Feature'.format('Ticket Frequency'), size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlmjgY_XTrk4"
   },
   "source": [
    "### **2.3 Title & Is Married**\n",
    "`Title` is created by extracting the prefix before `Name` feature. According to graph below, there are many titles that are occuring very few times. Some of those titles doesn't seem correct and they need to be replaced. **Miss**, **Mrs**, **Ms**, **Mlle**, **Lady**, **Mme**, **the Countess**, **Dona** titles are replaced with **Miss/Mrs/Ms** because all of them are female. Values like **Mlle**, **Mme** and **Dona** are actually the name of the passengers, but they are classified as titles because `Name` feature is split by comma. **Dr**, **Col**, **Major**, **Jonkheer**, **Capt**, **Sir**, **Don** and **Rev** titles are replaced with **Dr/Military/Noble/Clergy** because those passengers have similar characteristics. **Master** is a unique title. It is given to male passengers below age **26**. They have the highest survival rate among all males.\n",
    "\n",
    "`Is_Married` is a binary feature based on the **Mrs** title. **Mrs** title has the highest survival rate among other female titles. This title needs to be a feature because all female titles are grouped with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efgbaJkCTrk4"
   },
   "outputs": [],
   "source": [
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1628407429738,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "9NWIY3gPTrk4",
    "outputId": "1b70ad73-08ff-4128-e696-c9a7f7dd3ef4"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[0])\n",
    "\n",
    "axs[0].tick_params(axis='x', labelsize=10)\n",
    "axs[1].tick_params(axis='x', labelsize=15)\n",
    "\n",
    "for i in range(2):    \n",
    "    axs[i].tick_params(axis='y', labelsize=15)\n",
    "\n",
    "axs[0].set_title('Title Feature Value Counts', size=20, y=1.05)\n",
    "\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[1])\n",
    "axs[1].set_title('Title Feature Value Counts After Grouping', size=20, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMsWq3GpTrk4"
   },
   "source": [
    "### **2.4 Target Encoding**\n",
    "`extract_surname` function is used for extracting surnames of passengers from the `Name` feature. `Family` feature is created with the extracted surname. This is necessary for grouping passengers in the same family. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gz_oQL7VTrk5"
   },
   "outputs": [],
   "source": [
    "def extract_surname(data):    \n",
    "    \n",
    "    families = []\n",
    "    \n",
    "    for i in range(len(data)):        \n",
    "        name = data.iloc[i]\n",
    "\n",
    "        if '(' in name:\n",
    "            name_no_bracket = name.split('(')[0] \n",
    "        else:\n",
    "            name_no_bracket = name\n",
    "            \n",
    "        family = name_no_bracket.split(',')[0]\n",
    "        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n",
    "        \n",
    "        for c in string.punctuation:\n",
    "            family = family.replace(c, '').strip()\n",
    "            \n",
    "        families.append(family)\n",
    "            \n",
    "    return families\n",
    "\n",
    "df_all['Family'] = extract_surname(df_all['Name'])\n",
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wL8U3H2zTrk5"
   },
   "source": [
    "`Family_Survival_Rate` is calculated from families in training set since there is no `Survived` feature in test set. A list of family names that are occuring in both training and test set (`non_unique_families`), is created. The survival rate is calculated for families with more than 1 members in that list, and stored in `Family_Survival_Rate` feature.\n",
    "\n",
    "An extra binary feature `Family_Survival_Rate_NA` is created for families that are unique to the test set. This feature is also necessary because there is no way to calculate those families' survival rate. This feature implies that family survival rate is not applicable to those passengers because there is no way to retrieve their survival rate.\n",
    "\n",
    "`Ticket_Survival_Rate` and `Ticket_Survival_Rate_NA` features are also created with the same method. `Ticket_Survival_Rate` and `Family_Survival_Rate` are averaged and become `Survival_Rate`, and `Ticket_Survival_Rate_NA` and `Family_Survival_Rate_NA` are also averaged and become `Survival_Rate_NA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXc7m7YbTrk5"
   },
   "outputs": [],
   "source": [
    "# Creating a list of families and tickets that are occuring in both training and test set\n",
    "non_unique_families = [x for x in df_train['Family'].unique() if x in df_test['Family'].unique()]\n",
    "non_unique_tickets = [x for x in df_train['Ticket'].unique() if x in df_test['Ticket'].unique()]\n",
    "\n",
    "df_family_survival_rate = df_train.groupby('Family')['Survived', 'Family','Family_Size'].median()\n",
    "df_ticket_survival_rate = df_train.groupby('Ticket')['Survived', 'Ticket','Ticket_Frequency'].median()\n",
    "\n",
    "family_rates = {}\n",
    "ticket_rates = {}\n",
    "\n",
    "for i in range(len(df_family_survival_rate)):\n",
    "    # Checking a family exists in both training and test set, and has members more than 1\n",
    "    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\n",
    "        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]\n",
    "\n",
    "for i in range(len(df_ticket_survival_rate)):\n",
    "    # Checking a ticket exists in both training and test set, and has members more than 1\n",
    "    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\n",
    "        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "duYHdEAATrk5"
   },
   "outputs": [],
   "source": [
    "mean_survival_rate = np.mean(df_train['Survived'])\n",
    "\n",
    "train_family_survival_rate = []\n",
    "train_family_survival_rate_NA = []\n",
    "test_family_survival_rate = []\n",
    "test_family_survival_rate_NA = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    if df_train['Family'][i] in family_rates:\n",
    "        train_family_survival_rate.append(family_rates[df_train['Family'][i]])\n",
    "        train_family_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        train_family_survival_rate.append(mean_survival_rate)\n",
    "        train_family_survival_rate_NA.append(0)\n",
    "        \n",
    "for i in range(len(df_test)):\n",
    "    if df_test['Family'].iloc[i] in family_rates:\n",
    "        test_family_survival_rate.append(family_rates[df_test['Family'].iloc[i]])\n",
    "        test_family_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        test_family_survival_rate.append(mean_survival_rate)\n",
    "        test_family_survival_rate_NA.append(0)\n",
    "        \n",
    "df_train['Family_Survival_Rate'] = train_family_survival_rate\n",
    "df_train['Family_Survival_Rate_NA'] = train_family_survival_rate_NA\n",
    "df_test['Family_Survival_Rate'] = test_family_survival_rate\n",
    "df_test['Family_Survival_Rate_NA'] = test_family_survival_rate_NA\n",
    "\n",
    "train_ticket_survival_rate = []\n",
    "train_ticket_survival_rate_NA = []\n",
    "test_ticket_survival_rate = []\n",
    "test_ticket_survival_rate_NA = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    if df_train['Ticket'][i] in ticket_rates:\n",
    "        train_ticket_survival_rate.append(ticket_rates[df_train['Ticket'][i]])\n",
    "        train_ticket_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        train_ticket_survival_rate.append(mean_survival_rate)\n",
    "        train_ticket_survival_rate_NA.append(0)\n",
    "        \n",
    "for i in range(len(df_test)):\n",
    "    if df_test['Ticket'].iloc[i] in ticket_rates:\n",
    "        test_ticket_survival_rate.append(ticket_rates[df_test['Ticket'].iloc[i]])\n",
    "        test_ticket_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        test_ticket_survival_rate.append(mean_survival_rate)\n",
    "        test_ticket_survival_rate_NA.append(0)\n",
    "        \n",
    "df_train['Ticket_Survival_Rate'] = train_ticket_survival_rate\n",
    "df_train['Ticket_Survival_Rate_NA'] = train_ticket_survival_rate_NA\n",
    "df_test['Ticket_Survival_Rate'] = test_ticket_survival_rate\n",
    "df_test['Ticket_Survival_Rate_NA'] = test_ticket_survival_rate_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cz3GMxNoTrk5"
   },
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    df['Survival_Rate'] = (df['Ticket_Survival_Rate'] + df['Family_Survival_Rate']) / 2\n",
    "    df['Survival_Rate_NA'] = (df['Ticket_Survival_Rate_NA'] + df['Family_Survival_Rate_NA']) / 2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b39a06d42b89d64f59f51a21dabdc5fe27fdcdaa",
    "id": "5pwrz61-Trk5"
   },
   "source": [
    "### **2.5 Feature Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1HeRVxBTrk5"
   },
   "source": [
    "#### **2.5.1 Label Encoding Non-Numerical Features**\n",
    "`Embarked`, `Sex`, `Deck` , `Title` and `Family_Size_Grouped` are object type, and `Age` and `Fare` features are category type. They are converted to numerical type with `LabelEncoder`. `LabelEncoder` basically labels the classes from **0** to **n**. This process is necessary for models to learn from those features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1628407433429,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "pbiTE8LJo1YP",
    "outputId": "58b3b300-615e-4467-f97e-d82e31de6483"
   },
   "outputs": [],
   "source": [
    "dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1628407433429,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "Lp0K1UWKomGy",
    "outputId": "c7a67bf7-18a7-4e66-b522-45de594ecfb4"
   },
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    for feature in non_numeric_features:   \n",
    "      print(df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "We2yE2smTrk5"
   },
   "outputs": [],
   "source": [
    "non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature].astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2enZU1WTrk5"
   },
   "source": [
    "#### **2.5.2 One-Hot Encoding the Categorical Features**\n",
    "The categorical features (`Pclass`, `Sex`, `Deck`, `Embarked`, `Title`) are converted to one-hot encoded features with `OneHotEncoder`. `Age` and `Fare` features are not converted because they are ordinal unlike the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p3hy6TEaTrk6"
   },
   "outputs": [],
   "source": [
    "cat_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:6]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[6:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WchiqEP0Trk6"
   },
   "source": [
    "# [발표대상] **2.6 Conclusion**\n",
    "- 빈도 기반으로 변수처리 : Age, Fare  (이상값 처리에 좋음)\n",
    "- 파생변수 도출: 결혼여부(Name에서 추출), 가족생존율(Name의 성에서 추출)\n",
    "- 범주형 변수는 one-hot 인코딩으로 처리됨\n",
    "\n",
    "### **2.6 Conclusion**\n",
    "`Age` and `Fare` features are binned. Binning helped dealing with outliers and it revealed some homogeneous groups in those features. `Family_Size` is created by adding `Parch` and `SibSp` features and **1**. `Ticket_Frequency` is created by counting the occurence of `Ticket` values.\n",
    "\n",
    "`Name` feature is very useful. First, `Title` and `Is_Married` features are created from the title prefix in the names. Second, `Family_Survival_Rate` and `Family_Survival_Rate_NA`  features are created by target encoding the surname of the passengers. `Ticket_Survival_Rate` is created by target encoding the `Ticket` feature. `Survival_Rate` feature is created by averaging the `Family_Survival_Rate` and `Ticket_Survival_Rate` features.\n",
    "\n",
    "Finally, the non-numeric type features are label encoded and categorical features are one-hot encoded. Created **5** new features (`Family_Size`, `Title`, `Is_Married`, `Survival_Rate` and `Survival_Rate_NA`) and dropped the useless features after encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1628407445088,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "pFHaa2AETrk6",
    "outputId": "2cd6e5d9-6312-40bf-bbb3-94c45584cdd6"
   },
   "outputs": [],
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Deck', 'Embarked', 'Family', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n",
    "             'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'Title',\n",
    "            'Ticket_Survival_Rate', 'Family_Survival_Rate', 'Ticket_Survival_Rate_NA', 'Family_Survival_Rate_NA']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b3d47212b52113b53a3e6d0d0a4ee08aa97b02f",
    "id": "6GkiYeOuTrk6"
   },
   "source": [
    "## **3. Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1628407447568,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "KiJxwqdrTrk6",
    "outputId": "28182528-542e-4520-ff9c-74188480b8a4"
   },
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9QoZva0Trk6"
   },
   "source": [
    "### **3.1 Random Forest**\n",
    "Created 2 `RandomForestClassifier`'s. One of them is a single model and the other is for k-fold cross validation.\n",
    "\n",
    "The highest accuracy of the `single_best_model` is **0.82775** in public leaderboard. However, it doesn't perform better in k-fold cross validation. It is a good model to start experimenting and hyperparameter tuning.\n",
    "\n",
    "The highest accuracy of `leaderboard_model` is **0.83732** in public leaderboard with 5-fold cross validation. This model is created for leaderboard score and it is tuned to overfit slightly. It is designed to overfit because the estimated probabilities of `X_test` in every fold are going to be divided by **N** (fold count). If this model is used as a single model, it would struggle to predict lots of samples correctly.\n",
    "\n",
    "**Which model should I use?** \n",
    "* `leaderboard_model` overfits to test set so it's not suggested to use models like this in real life projects.\n",
    "* `single_best_model` is a good model to start experimenting and learning about decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faP0X019Trk6"
   },
   "outputs": [],
   "source": [
    "single_best_model = RandomForestClassifier(criterion='gini', \n",
    "                                           n_estimators=1100,\n",
    "                                           max_depth=5,\n",
    "                                           min_samples_split=4,\n",
    "                                           min_samples_leaf=5,\n",
    "                                           max_features='auto',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=SEED,\n",
    "                                           n_jobs=-1,\n",
    "                                           verbose=1)\n",
    "\n",
    "leaderboard_model = RandomForestClassifier(criterion='gini',\n",
    "                                           n_estimators=1750,\n",
    "                                           max_depth=7,\n",
    "                                           min_samples_split=6,\n",
    "                                           min_samples_leaf=6,\n",
    "                                           max_features='auto',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=SEED,\n",
    "                                           n_jobs=-1,\n",
    "                                           verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKfe94WOTrk6"
   },
   "source": [
    "`StratifiedKFold` is used for stratifying the target variable. The folds are made by preserving the percentage of samples for each class in target variable (`Survived`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35344,
     "status": "ok",
     "timestamp": 1628407488345,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "BRRumpy2Trk6",
    "outputId": "5b8cab1e-2cbb-4b3d-e49d-9777eb5858ed"
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "oob = 0\n",
    "probs = pd.DataFrame(np.zeros((len(X_test), N * 2)), columns=['Fold_{}_Prob_{}'.format(i, j) for i in range(1, N + 1) for j in range(2)])\n",
    "importances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=df_all.columns)\n",
    "fprs, tprs, scores = [], [], []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    print('Fold {}\\n'.format(fold))\n",
    "    \n",
    "    # Fitting the model\n",
    "    leaderboard_model.fit(X_train[trn_idx], y_train[trn_idx])\n",
    "    \n",
    "    # Computing Train AUC score\n",
    "    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx], leaderboard_model.predict_proba(X_train[trn_idx])[:, 1])\n",
    "    trn_auc_score = auc(trn_fpr, trn_tpr)\n",
    "    # Computing Validation AUC score\n",
    "    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx], leaderboard_model.predict_proba(X_train[val_idx])[:, 1])\n",
    "    val_auc_score = auc(val_fpr, val_tpr)  \n",
    "      \n",
    "    scores.append((trn_auc_score, val_auc_score))\n",
    "    fprs.append(val_fpr)\n",
    "    tprs.append(val_tpr)\n",
    "    \n",
    "    # X_test probabilities\n",
    "    probs.loc[:, 'Fold_{}_Prob_0'.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 0]\n",
    "    probs.loc[:, 'Fold_{}_Prob_1'.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 1]\n",
    "    importances.iloc[:, fold - 1] = leaderboard_model.feature_importances_\n",
    "        \n",
    "    oob += leaderboard_model.oob_score_ / N\n",
    "    print('Fold {} OOB Score: {}\\n'.format(fold, leaderboard_model.oob_score_))   \n",
    "    \n",
    "print('Average OOB Score: {}'.format(oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dh71T17FTrk6"
   },
   "source": [
    "### **3.2 Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 855
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1628407488345,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "BFLK_2ZCMNmA",
    "outputId": "edda1dc8-65a8-4268-d2ee-56b583c3672a"
   },
   "outputs": [],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1002,
     "status": "ok",
     "timestamp": 1628407489338,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "X_ACQSwuTrk6",
    "outputId": "9ed74467-3804-4600-9801-ff41507d112d"
   },
   "outputs": [],
   "source": [
    "importances['Mean_Importance'] = importances.mean(axis=1)\n",
    "importances.sort_values(by='Mean_Importance', inplace=True, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "sns.barplot(x='Mean_Importance', y=importances.index, data=importances)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "plt.title('Random Forest Classifier Mean Feature Importance Between Folds', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RAFfvDWTrk7"
   },
   "source": [
    "### **3.3 ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 943
    },
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1628407490147,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "_CcxZvcgTrk7",
    "outputId": "3901dda1-0a4e-402c-f091-dfe8134e9be7"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fprs, tprs):\n",
    "    \n",
    "    tprs_interp = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    f, ax = plt.subplots(figsize=(15, 15))\n",
    "    \n",
    "    # Plotting ROC for each fold and computing AUC scores\n",
    "    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):\n",
    "        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs_interp[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC Fold {} (AUC = {:.3f})'.format(i, roc_auc))\n",
    "        \n",
    "    # Plotting ROC for random guessing\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8, label='Random Guessing')\n",
    "    \n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    # Plotting the mean ROC\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc), lw=2, alpha=0.8)\n",
    "    \n",
    "    # Plotting the standard deviation around the mean ROC Curve\n",
    "    std_tpr = np.std(tprs_interp, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label='$\\pm$ 1 std. dev.')\n",
    "    \n",
    "    ax.set_xlabel('False Positive Rate', size=15, labelpad=20)\n",
    "    ax.set_ylabel('True Positive Rate', size=15, labelpad=20)\n",
    "    ax.tick_params(axis='x', labelsize=15)\n",
    "    ax.tick_params(axis='y', labelsize=15)\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "\n",
    "    ax.set_title('ROC Curves of Folds', size=20, y=1.02)\n",
    "    ax.legend(loc='lower right', prop={'size': 13})\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fprs, tprs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8154ae17f15be72790a702ca957d6bbf40029705",
    "id": "IxPQhDTcTrk7"
   },
   "source": [
    "### **3.4 Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1628407490148,
     "user": {
      "displayName": "CEO Jung",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhrtBIJPY2gjsuySGAqGqII1ocHChE_Y7uF1dWe=s64",
      "userId": "04795185056376255241"
     },
     "user_tz": -540
    },
    "id": "OKQ89WXHTrk7",
    "outputId": "9b4c99cf-f596-4740-8725-fd31f6216b0c"
   },
   "outputs": [],
   "source": [
    "class_survived = [col for col in probs.columns if col.endswith('Prob_1')]\n",
    "probs['1'] = probs[class_survived].sum(axis=1) / N\n",
    "probs['0'] = probs.drop(columns=class_survived).sum(axis=1) / N\n",
    "probs['pred'] = 0\n",
    "pos = probs[probs['1'] >= 0.5].index\n",
    "probs.loc[pos, 'pred'] = 1\n",
    "\n",
    "y_pred = probs['pred'].astype(int)\n",
    "\n",
    "submission_df = pd.DataFrame(columns=['PassengerId', 'Survived'])\n",
    "submission_df['PassengerId'] = df_test['PassengerId']\n",
    "submission_df['Survived'] = y_pred.values\n",
    "submission_df.to_csv('submissions.csv', header=True, index=False)\n",
    "submission_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0yO9ngXpgbd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "titanic-advanced-feature-engineering-tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
